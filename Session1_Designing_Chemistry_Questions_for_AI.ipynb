{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bcd24d0d",
      "metadata": {
        "id": "bcd24d0d"
      },
      "source": [
        "\n",
        "# Designing Chemistry Questions for AI  \n",
        "*Session 1: Using LLM APIs for Chemical Reasoning*\n",
        "\n",
        "**What you'll do in this session**\n",
        "- Understand what a Large Language Model (LLM) is and why chemists might use one.\n",
        "- Run a **simple, click-to-run demo** that asks a chemistry question.\n",
        "- Write your **own prompt** and see how wording changes answers.\n",
        "- Reflect on what to **trust vs. verify** (textbook, PubChem, literature).\n",
        "\n",
        "> No prior coding needed. We‚Äôll use buttons and text boxes. Code cells are short and explained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b5708b",
      "metadata": {
        "id": "73b5708b"
      },
      "source": [
        "\n",
        "## üß™ Introduction\n",
        "\n",
        "**Large Language Models (LLMs)** like GPT-4 can answer questions in natural language. They are trained on vast amounts of text\n",
        "and can *explain*, *compare*, and *summarize* chemistry topics.\n",
        "\n",
        "**Quick examples**\n",
        "- **Q:** What is the chemical formula of water?  \n",
        "  **A:** H‚ÇÇO  \n",
        "- **Q:** Why is water polar?  \n",
        "  **A:** Oxygen is more electronegative than hydrogen, creating a dipole moment.\n",
        "\n",
        "**Important mindset**\n",
        "- LLMs are powerful, but they can **hallucinate** (confident mistakes).  \n",
        "- You should **verify** numbers and claims with trusted sources (textbook, PubChem, literature).  \n",
        "- **Prompt wording matters**: adding details or constraints can improve answers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6b55bb",
      "metadata": {
        "id": "0c6b55bb"
      },
      "source": [
        "\n",
        "## ‚úÖ Setup (Instructions)\n",
        "1. Run the next **Code** cell to install packages and import basics.  \n",
        "2. Then, add your **OpenAI API key** in the following cell (kept hidden).  \n",
        "3. If you *don't* have a key, the notebook still runs in **demo mode** with safe placeholder answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12bef81d",
      "metadata": {
        "id": "12bef81d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# install and import required packages\n",
        "# - openai ‚Üí to connect to GPT models\n",
        "# - ipywidgets ‚Üí to build interactive buttons, text boxes\n",
        "!pip -q install openai ipywidgets\n",
        "!pip install -q openai\n",
        "\n",
        "\n",
        "import os # handle environment variables (API key storage)\n",
        "from IPython.display import display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from openai import OpenAI # OpenAI client\n",
        "\n",
        "display(Markdown(\"> **Setup ready.** Next: add your OpenAI API key.\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7722de06",
      "metadata": {
        "id": "7722de06"
      },
      "source": [
        "\n",
        "## üîë Add Your OpenAI API Key (Hidden Input)\n",
        "\n",
        "- Paste your API key in the box and click **Save Key**.  \n",
        "- Your key is stored only in this session's memory.  \n",
        "- If this step is skipped, the notebook will return a **demo placeholder** answer instead of contacting the API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df76542c",
      "metadata": {
        "id": "df76542c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Hidden password box for API key + a \"Save Key\" button\n",
        "api_key_box = widgets.Password(\n",
        "    description='API Key:',\n",
        "    placeholder='sk-...',\n",
        "    layout=widgets.Layout(width='40%')\n",
        ")\n",
        "\n",
        "# Button to save the key\n",
        "\n",
        "save_btn = widgets.Button(description='Save Key', button_style='primary')\n",
        "\n",
        "# Status message (will show \"‚úÖ saved\" or \"‚ö†Ô∏è error\")\n",
        "\n",
        "status = widgets.HTML(\"\")\n",
        "\n",
        "# Function runs when button is clicked\n",
        "\n",
        "def save_key(_):\n",
        "    if api_key_box.value.strip():   # if box is not empty\n",
        "        os.environ[\"OPENAI_API_KEY\"] = api_key_box.value.strip()\n",
        "        status.value = \"<span style='color:green'>‚úÖ Key saved for this session.</span>\"\n",
        "    else:\n",
        "        status.value = \"<span style='color:#B00020'>‚ö†Ô∏è Please paste a valid key.</span>\"\n",
        "\n",
        "# Connect button to function\n",
        "save_btn.on_click(save_key)\n",
        "\n",
        "display(widgets.HBox([api_key_box, save_btn]))\n",
        "display(status)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe273c74",
      "metadata": {
        "id": "fe273c74"
      },
      "source": [
        "\n",
        "## üß© Helper Functions (What this cell does)\n",
        "The next code cell defines two small helpers:\n",
        "- `get_client()` ‚Äî creates an OpenAI client **if** a key is present.\n",
        "- `ask_llm(prompt, model)` ‚Äî sends your question to the model and returns the answer.  \n",
        "  If no key is set, you‚Äôll get a **demo placeholder** so the notebook still works for everyone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b8eec96",
      "metadata": {
        "id": "4b8eec96"
      },
      "outputs": [],
      "source": [
        "# Get an OpenAI client object if key is available\n",
        "def get_client():\n",
        "    key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    return OpenAI(api_key=key) if key else None\n",
        "\n",
        "\n",
        "\n",
        "# Ask the model a question\n",
        "def ask_llm(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"Ask the model one question. Uses a fallback if no key is set.\"\"\"\n",
        "    client = get_client()\n",
        "    if client is None:\n",
        "        return (\"*(Demo mode: no API key found.)*\\n\\n\"\n",
        "                \"This is a placeholder answer. With a real key, the model would respond here.\")\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,  # try 'gpt-4o-mini' (fast) or 'gpt-4o' (quality); 'gpt-3.5-turbo' also available\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        return completion.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"*API error:* `{e}`\"\n",
        "\n",
        "display(Markdown(\"> **Helper ready.** Next: run the Demo section below.\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66458ddd",
      "metadata": {
        "id": "66458ddd"
      },
      "source": [
        "\n",
        "## üí° Demo (Click-to-Run)\n",
        "\n",
        "We will ask a fixed question and display the answer:\n",
        "\n",
        "**Question:** *What is the difference between benzene and toluene?*\n",
        "\n",
        "**What to look for**\n",
        "- Does it mention that **toluene = benzene + methyl group (‚ÄìCH‚ÇÉ)**?\n",
        "- Does it mention **property differences** (e.g., boiling point, polarity)?\n",
        "\n",
        "> Click the button below to run the demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1bafa6",
      "metadata": {
        "id": "be1bafa6"
      },
      "outputs": [],
      "source": [
        "\n",
        "demo_question = \"What is the difference between benzene and toluene?\"\n",
        "\n",
        "# Dropdown menu for model choice\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=[(\"gpt-4o-mini (fast)\", \"gpt-4o-mini\"),\n",
        "             (\"gpt-4o (quality)\", \"gpt-4o\"),\n",
        "             (\"gpt-3.5-turbo (legacy)\", \"gpt-3.5-turbo\")],\n",
        "    value=\"gpt-4o-mini\",\n",
        "    description=\"Model:\"\n",
        ")\n",
        "\n",
        "demo_btn = widgets.Button(description=\"Get Answer\", button_style=\"success\")\n",
        "demo_out = widgets.Output()\n",
        "\n",
        "# Function: runs when button clicked\n",
        "\n",
        "def on_demo_click(_):\n",
        "    demo_out.clear_output()\n",
        "    with demo_out:\n",
        "        display(Markdown(\"‚è≥ Asking the model...\"))\n",
        "    ans = ask_llm(demo_question, model=model_dropdown.value)\n",
        "\n",
        "\n",
        "    # Add a structure note (a handy fact)\n",
        "\n",
        "    structure_note = (\n",
        "        \"**Structure note:**\\n\"\n",
        "        \"- **Benzene:** aromatic ring C‚ÇÜH‚ÇÜ\\n\"\n",
        "        \"- **Toluene:** benzene ring with a methyl group (‚ÄìCH‚ÇÉ), formula C‚ÇáH‚Çà\\n\"\n",
        "    )\n",
        "\n",
        "    demo_out.clear_output()\n",
        "    with demo_out:\n",
        "        display(Markdown(\n",
        "            f\"### Demo Answer\\n\"\n",
        "            f\"**Q:** {demo_question}\\n\\n\"\n",
        "            f\"{structure_note}\\n\\n\"\n",
        "            f\"**Model‚Äôs explanation:**\\n\\n{ans}\"\n",
        "        ))\n",
        "\n",
        "demo_btn.on_click(on_demo_click)\n",
        "display(widgets.VBox([model_dropdown, demo_btn, demo_out]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öñÔ∏è Spot the Better Prompt (Side-by-Side)\n",
        "\n",
        "We‚Äôll compare two versions of the **same** chemistry question.  \n",
        "Before running, decide which you think will produce a **clearer, more useful** answer.\n",
        "\n",
        "**Example pair**\n",
        "- **Prompt A:** \"What is benzene?\"\n",
        "- **Prompt B:** \"Explain benzene‚Äôs structure, uses, and hazards in 3 bullet points.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Cmn3aK2WUvjQ"
      },
      "id": "Cmn3aK2WUvjQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# You can modify these prompt pairs according to you\"\n",
        "PROMPT_A = \"What is benzene?\"\n",
        "PROMPT_B = \"Explain benzene‚Äôs structure, uses, and hazards in 3 bullet points.\"\n",
        "\n",
        "spot_model = widgets.Dropdown(\n",
        "    options=[(\"gpt-4o-mini (fast)\", \"gpt-4o-mini\"),\n",
        "             (\"gpt-4o (quality)\", \"gpt-4o\"),\n",
        "             (\"gpt-3.5-turbo (legacy)\", \"gpt-3.5-turbo\")],\n",
        "    value=\"gpt-4o-mini\",\n",
        "    description=\"Model:\"\n",
        ")\n",
        "\n",
        "run_both_btn = widgets.Button(description=\"Run Both\", button_style=\"success\")\n",
        "spot_out = widgets.Output()\n",
        "\n",
        "def run_both(_):\n",
        "    spot_out.clear_output()\n",
        "    with spot_out:\n",
        "        display(Markdown(\"‚è≥ Asking the model for **Prompt A** and **Prompt B**...\"))\n",
        "    ans_a = ask_llm(PROMPT_A, model=spot_model.value)\n",
        "    ans_b = ask_llm(PROMPT_B, model=spot_model.value)\n",
        "    spot_out.clear_output()\n",
        "    with spot_out:\n",
        "        display(Markdown(\n",
        "            f\"### Results\\n\"\n",
        "            f\"**Prompt A:** {PROMPT_A}\\n\\n\"\n",
        "            f\"{ans_a}\\n\\n\"\n",
        "            f\"---\\n\"\n",
        "            f\"**Prompt B:** {PROMPT_B}\\n\\n\"\n",
        "            f\"{ans_b}\\n\"\n",
        "        ))\n",
        "\n",
        "run_both_btn.on_click(run_both)\n",
        "\n",
        "display(widgets.VBox([spot_model, run_both_btn, spot_out]))\n"
      ],
      "metadata": {
        "id": "VpbggJFjUxkt"
      },
      "id": "VpbggJFjUxkt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "09c9c586",
      "metadata": {
        "id": "09c9c586"
      },
      "source": [
        "\n",
        "## ‚úçÔ∏è Exercise (Your Turn)\n",
        "\n",
        "- **Design your own prompt** (free text, any chemistry question).  \n",
        "- **Run** your prompt through the model.  \n",
        "- **Share** interesting prompts/outputs with your group.\n",
        "\n",
        "üîé *Look for surprising or incorrect outputs. Can you refine your prompt to improve the answer?*  \n",
        "Try adding details like *‚Äúexplain briefly,‚Äù ‚Äúcompare typical boiling points,‚Äù or ‚Äúgive two bullet points.‚Äù*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4481935d",
      "metadata": {
        "id": "4481935d"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_box = widgets.Textarea(\n",
        "    placeholder=\"Type your chemistry question here (e.g., Why does salt dissolve in water?)\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"90px\")\n",
        ")\n",
        "model_picker = widgets.Dropdown(\n",
        "    options=[(\"gpt-4o-mini (fast)\", \"gpt-4o-mini\"),\n",
        "             (\"gpt-4o (quality)\", \"gpt-4o\"),\n",
        "             (\"gpt-3.5-turbo (legacy)\", \"gpt-3.5-turbo\")],\n",
        "    value=\"gpt-4o-mini\",\n",
        "    description=\"Model:\"\n",
        ")\n",
        "run_btn = widgets.Button(description=\"Ask\", button_style=\"primary\")\n",
        "exercise_out = widgets.Output()\n",
        "\n",
        "def on_run(_):\n",
        "    exercise_out.clear_output()\n",
        "    user_q = prompt_box.value.strip()\n",
        "    if not user_q:\n",
        "        with exercise_out:\n",
        "            display(Markdown(\"*Please type a question above.*\"))\n",
        "        return\n",
        "    with exercise_out:\n",
        "        display(Markdown(\"‚è≥ Asking the model...\"))\n",
        "    ans = ask_llm(user_q, model=model_picker.value)\n",
        "    exercise_out.clear_output()\n",
        "    with exercise_out:\n",
        "        display(Markdown(f\"**Q:** {user_q}\\n\\n**A:**\\n\\n{ans}\"))\n",
        "\n",
        "run_btn.on_click(on_run)\n",
        "display(widgets.VBox([prompt_box, model_picker, run_btn, exercise_out]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90344005",
      "metadata": {
        "id": "90344005"
      },
      "source": [
        "\n",
        "## üìò Reflection (Discuss / Note Down)\n",
        "- Did the answer include anything you would **double-check** in a trusted source (textbook, PubChem, literature)?  \n",
        "- What small change to your **prompt** improved the answer the most?  \n",
        "- If the model gave a **numerical property**, how would you verify it?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da9b3f1",
      "metadata": {
        "id": "5da9b3f1"
      },
      "source": [
        "\n",
        "## üõ†Ô∏è Troubleshooting\n",
        "- If buttons don‚Äôt appear or do nothing, **Runtime ‚Üí Restart runtime** and re-run the Setup cell.\n",
        "- If you see `API error`, double-check your **API key** and internet connection.\n",
        "- If you have **no key**, you will see a *demo placeholder* answer instead of a real model response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9d6b8c",
      "metadata": {
        "id": "5a9d6b8c"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Has API key? \", \"‚úÖ\" if \"OPENAI_API_KEY\" in os.environ else \"‚ùå\")\n",
        "try:\n",
        "    import openai  # confirm package presence\n",
        "    print(\"openai package import: ‚úÖ\")\n",
        "except Exception as e:\n",
        "    print(\"openai package import: ‚ùå\", e)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}